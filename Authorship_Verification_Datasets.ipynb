{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD+ZcXvpuEhEFg+g4MuVGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swan-07/authorship-verification/blob/main/Authorship_Verification_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gu_cU3yRKtj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import random\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "#same author = 1, diff = 0\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "MFjRZPX5WwVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "lXLcPGUiXOXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def replace_named_entities(texts):\n",
        "    processed_texts = []\n",
        "\n",
        "    # Use tqdm for progress indication\n",
        "    for doc in tqdm(nlp.pipe(texts, batch_size=50), total=len(texts)):\n",
        "        new_text = []\n",
        "        last_idx = 0\n",
        "        for ent in doc.ents:\n",
        "            new_text.append(doc.text[last_idx:ent.start_char])\n",
        "            new_text.append(ent.label_)\n",
        "            last_idx = ent.end_char\n",
        "        new_text.append(doc.text[last_idx:])\n",
        "        processed_texts.append(\"\".join(new_text))\n",
        "\n",
        "    return processed_texts"
      ],
      "metadata": {
        "id": "RCPHisANTwmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lengths_df(df):\n",
        "    average_length_text1 = df['text1'].apply(len).mean()\n",
        "    average_length_text2 = df['text2'].apply(len).mean()\n",
        "\n",
        "    # Calculate the overall average length of texts\n",
        "    overall_average_length = (average_length_text1 + average_length_text2) / 2\n",
        "\n",
        "    # Get the total number of rows\n",
        "    total_rows = len(df)\n",
        "\n",
        "    print(f'Average length of text1: {average_length_text1:.2f} characters')\n",
        "    print(f'Average length of text2: {average_length_text2:.2f} characters')\n",
        "    print(f'Overall average length of texts: {overall_average_length:.2f} characters')\n",
        "    print(f'Total number of rows: {total_rows}')"
      ],
      "metadata": {
        "id": "q6KliuJYXePk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def read_texts(directory: str):\n",
        "    texts_by_author = {}\n",
        "\n",
        "    files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
        "    for file in files:\n",
        "        author_id = file.split('.')[0][:-1]  # Extract author ID by removing the last character and the file extension\n",
        "        file_path = os.path.join(directory, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            text = f.read()\n",
        "            if author_id not in texts_by_author:\n",
        "                texts_by_author[author_id] = []\n",
        "            texts_by_author[author_id].append(text)\n",
        "\n",
        "    return texts_by_author\n"
      ],
      "metadata": {
        "id": "BbM-mcKSc6mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pairs(data, reserve_ratio=0.5):\n",
        "    same_author_pairs = []\n",
        "    different_author_pairs = []\n",
        "\n",
        "    # Create pairs of texts with the same label (same = 1)\n",
        "    used_texts = set()\n",
        "    reserved_texts = []\n",
        "\n",
        "    for label, texts in data.items():\n",
        "        random.shuffle(texts)  # Shuffle texts to randomly reserve some\n",
        "        num_reserve = int(len(texts) * reserve_ratio)\n",
        "\n",
        "        # Reserve a portion of the texts for different author pairs\n",
        "        available_texts = texts[num_reserve:]\n",
        "        reserved_texts.extend((label, text) for text in texts[:num_reserve])\n",
        "\n",
        "        while len(available_texts) > 1:\n",
        "            text1 = available_texts.pop()\n",
        "            text2 = available_texts.pop()\n",
        "            same_author_pairs.append((text1, text2, 1))\n",
        "            used_texts.add(text1)\n",
        "            used_texts.add(text2)\n",
        "\n",
        "    # Create pairs of texts with different labels (same = 0)\n",
        "    while len(reserved_texts) > 1:\n",
        "        (label1, text1), (label2, text2) = random.sample(reserved_texts, 2)\n",
        "        if label1 != label2:\n",
        "            different_author_pairs.append((text1, text2, 0))\n",
        "            reserved_texts.remove((label1, text1))\n",
        "            reserved_texts.remove((label2, text2))\n",
        "            used_texts.add(text1)\n",
        "            used_texts.add(text2)\n",
        "\n",
        "    print(f'Same author pairs: {len(same_author_pairs)}')\n",
        "    print(f'Different author pairs: {len(different_author_pairs)}')\n",
        "\n",
        "    # Balance the number of pairs\n",
        "    min_size = min(len(same_author_pairs), len(different_author_pairs))\n",
        "    balanced_same_author_pairs = random.sample(same_author_pairs, min_size)\n",
        "    balanced_different_author_pairs = random.sample(different_author_pairs, min_size)\n",
        "\n",
        "    # Combine and shuffle the pairs\n",
        "    balanced_pairs = balanced_same_author_pairs + balanced_different_author_pairs\n",
        "    random.shuffle(balanced_pairs)\n",
        "\n",
        "    return balanced_pairs"
      ],
      "metadata": {
        "id": "btqJLYFHc8WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_test_val_split(df, train_size=0.7, val_size=0.15, test_size=0.15, random_state=None):\n",
        "    # Ensure the sizes add up to 1.0\n",
        "    assert train_size + val_size + test_size == 1.0, \"Train, validation, and test sizes must add up to 1.0\"\n",
        "\n",
        "    # Split the DataFrame into train and temp (val + test)\n",
        "    train_df, temp_df = train_test_split(df, train_size=train_size, random_state=random_state)\n",
        "\n",
        "    # Split the temp DataFrame into validation and test sets\n",
        "    relative_val_size = val_size / (val_size + test_size)\n",
        "    val_df, test_df = train_test_split(temp_df, train_size=relative_val_size, random_state=random_state)\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dZyeRlrkUdL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def parse_training_text(file_path):\n",
        "    data = {'text': [], 'id': []}\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    entries = content.split('<text file=')\n",
        "\n",
        "    for entry in entries[1:]:  # Skip the first split as it's before the first <text file=\n",
        "        try:\n",
        "            author_id = entry.split('<author id=\"')[1].split('\"/>')[0]\n",
        "            body_text = entry.split('<body>')[1].split('</body>')[0].strip()\n",
        "            body_text = ' '.join(body_text.split())  # Normalize whitespace\n",
        "\n",
        "            data['text'].append(body_text)\n",
        "            data['id'].append(author_id)\n",
        "        except IndexError as e:\n",
        "            # Skip malformed entries\n",
        "            print(f\"Skipping malformed entry due to IndexError: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "jYVUrf7odg0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_unique_text_pairs(data, reserve_ratio=0.5):\n",
        "    same_author_pairs = []\n",
        "    different_author_pairs = []\n",
        "\n",
        "    # Create pairs of texts with the same label (same = 1)\n",
        "    used_texts = set()\n",
        "    reserved_texts = []\n",
        "\n",
        "    for label, texts in data.items():\n",
        "        random.shuffle(texts)  # Shuffle texts to randomly reserve some\n",
        "        num_reserve = int(len(texts) * reserve_ratio)\n",
        "\n",
        "        # Reserve a portion of the texts for different author pairs\n",
        "        available_texts = texts[num_reserve:]\n",
        "        reserved_texts.extend((label, text) for text in texts[:num_reserve])\n",
        "\n",
        "        while len(available_texts) > 1:\n",
        "            text1 = available_texts.pop()\n",
        "            text2 = available_texts.pop()\n",
        "            same_author_pairs.append((text1, text2, 1))\n",
        "            used_texts.add(text1)\n",
        "            used_texts.add(text2)\n",
        "\n",
        "    # Create pairs of texts with different labels (same = 0)\n",
        "    while len(reserved_texts) > 1:\n",
        "        (label1, text1), (label2, text2) = random.sample(reserved_texts, 2)\n",
        "        if label1 != label2:\n",
        "            different_author_pairs.append((text1, text2, 0))\n",
        "            reserved_texts.remove((label1, text1))\n",
        "            reserved_texts.remove((label2, text2))\n",
        "            used_texts.add(text1)\n",
        "            used_texts.add(text2)\n",
        "\n",
        "    print(len(same_author_pairs))\n",
        "    print(len(different_author_pairs))\n",
        "\n",
        "    # Balance the number of pairs\n",
        "    min_size = min(len(same_author_pairs), len(different_author_pairs))\n",
        "    balanced_same_author_pairs = random.sample(same_author_pairs, min_size)\n",
        "    balanced_different_author_pairs = random.sample(different_author_pairs, min_size)\n",
        "\n",
        "    # Combine and shuffle the pairs\n",
        "    balanced_pairs = balanced_same_author_pairs + balanced_different_author_pairs\n",
        "    random.shuffle(balanced_pairs)\n",
        "\n",
        "    return balanced_pairs"
      ],
      "metadata": {
        "id": "yVySj8uqUejd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_darkreddit(directory: str):\n",
        "    splits = ['train', 'test', 'val']\n",
        "    data = {split: [] for split in splits}\n",
        "\n",
        "    for split in splits:\n",
        "        split_dir = os.path.join(directory, split)\n",
        "        files = [f for f in os.listdir(split_dir) if f.endswith('.json')]\n",
        "        print(f'Number of JSON files in {split} split: {len(files)}')\n",
        "\n",
        "        for file in tqdm(files, desc=f'Processing {split} files'):\n",
        "            file_path = os.path.join(split_dir, file)\n",
        "            with open(file_path, 'r') as f:\n",
        "                content = json.load(f)\n",
        "                text1_cleaned = remove_named_entities(content['pair'][0])\n",
        "                text2_cleaned = remove_named_entities(content['pair'][1])\n",
        "                data[split].append({\n",
        "                    'text1': text1_cleaned,\n",
        "                    'text2': text2_cleaned,\n",
        "                    'same': 1 if content['same'] else 0\n",
        "                })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    train_df = pd.DataFrame(data['train'])\n",
        "    test_df = pd.DataFrame(data['test'])\n",
        "    val_df = pd.DataFrame(data['val'])\n",
        "\n",
        "    return train_df, test_df, val_df"
      ],
      "metadata": {
        "id": "lM88zcjhcBRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_pairs(df, reserve_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Create a balanced dataset with text pairs and a label indicating if they are from the same author.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): Input DataFrame containing 'id' and 'text' columns.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with columns 'text1', 'text2', and 'same'.\n",
        "    \"\"\"\n",
        "    # Create a dictionary to group texts by IDs\n",
        "    id_to_texts = df.groupby('id')['text'].apply(list).to_dict()\n",
        "\n",
        "    same_author_pairs = []\n",
        "    different_author_pairs = []\n",
        "    used_texts = set()\n",
        "\n",
        "    # Create same author pairs and reserve some texts\n",
        "    reserved_texts = []\n",
        "\n",
        "    for id, texts in tqdm(id_to_texts.items(), desc=\"Creating same author pairs and reserving texts\"):\n",
        "        random.shuffle(texts)\n",
        "        num_reserve = int(len(texts) * reserve_ratio)\n",
        "        available_texts = texts[num_reserve:]\n",
        "        reserved_texts.extend((id, text) for text in texts[:num_reserve])\n",
        "\n",
        "        for i in range(0, len(available_texts) - 1, 2):\n",
        "            if i + 1 < len(available_texts):\n",
        "                same_author_pairs.append((available_texts[i], available_texts[i + 1], 1))\n",
        "                used_texts.add(available_texts[i])\n",
        "                used_texts.add(available_texts[i + 1])\n",
        "\n",
        "    print(f\"Number of same author pairs: {len(same_author_pairs)}\")\n",
        "\n",
        "    # Create different author pairs using reserved texts\n",
        "    num_iterations = len(reserved_texts) // 2  # Estimate number of iterations\n",
        "    with tqdm(total=num_iterations, desc=\"Creating different author pairs\") as pbar:\n",
        "        while len(reserved_texts) > 1:\n",
        "            (id1, text1), (id2, text2) = random.sample(reserved_texts, 2)\n",
        "            if id1 != id2:\n",
        "                different_author_pairs.append((text1, text2, 0))\n",
        "                reserved_texts.remove((id1, text1))\n",
        "                reserved_texts.remove((id2, text2))\n",
        "                used_texts.add(text1)\n",
        "                used_texts.add(text2)\n",
        "                pbar.update(1)\n",
        "\n",
        "    print(f\"Number of different author pairs: {len(different_author_pairs)}\")\n",
        "\n",
        "    # Balance the number of pairs\n",
        "    min_size = min(len(same_author_pairs), len(different_author_pairs))\n",
        "    balanced_same_author_pairs = random.sample(same_author_pairs, min_size)\n",
        "    balanced_different_author_pairs = random.sample(different_author_pairs, min_size)\n",
        "\n",
        "    # Combine and shuffle the pairs\n",
        "    balanced_pairs = balanced_same_author_pairs + balanced_different_author_pairs\n",
        "    random.shuffle(balanced_pairs)\n",
        "\n",
        "    # Create a DataFrame from the balanced pairs\n",
        "    balanced_df = pd.DataFrame(balanced_pairs, columns=['text1', 'text2', 'same'])\n",
        "\n",
        "    return balanced_df"
      ],
      "metadata": {
        "id": "2w0fcnKqT5G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download(df, df_name):\n",
        "\n",
        "    # Split the combined dataframe\n",
        "    train, val, test = train_test_val_split(df, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42)\n",
        "\n",
        "    # Display the sizes of the resulting DataFrames\n",
        "    print(f'Train set size: {len(train)}')\n",
        "    print(f'Validation set size: {len(val)}')\n",
        "    print(f'Test set size: {len(test)}')\n",
        "\n",
        "    train.to_csv(f'Desktop/{df_name}_train.csv', index=False)\n",
        "    val.to_csv(f'Desktop/{df_name}_val.csv', index=False)\n",
        "    test.to_csv(f'Desktop/{df_name}_test.csv', index=False)"
      ],
      "metadata": {
        "id": "X_0X7CQrj1n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_folder(directory):\n",
        "    # Reading the truth file\n",
        "    truth_file_path = os.path.join(directory, 'truth.txt')\n",
        "    labels = {}\n",
        "    with open(truth_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 2:  # Ensure there are exactly 2 parts\n",
        "                folder_name, same_author = parts\n",
        "                labels[folder_name] = same_author == 'Y'\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for folder in os.listdir(directory):\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            known_file_path = os.path.join(folder_path, 'known01.txt')\n",
        "            unknown_file_path = os.path.join(folder_path, 'unknown.txt')\n",
        "\n",
        "            with open(known_file_path, 'r', errors='ignore') as file:\n",
        "                text1 = file.read()\n",
        "\n",
        "            with open(unknown_file_path, 'r', errors='ignore') as file:\n",
        "                text2 = file.read()\n",
        "\n",
        "            same = labels.get(folder, False)  # Default to False if folder not found in truth.txt\n",
        "            data.append((text1, text2, same))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['text1', 'text2', 'same'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "rOt-bf7ufAYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lengths_df(df):\n",
        "    average_length_text1 = df['text1'].apply(len).mean()\n",
        "    average_length_text2 = df['text2'].apply(len).mean()\n",
        "\n",
        "    # Calculate the overall average length of texts\n",
        "    overall_average_length = (average_length_text1 + average_length_text2) / 2\n",
        "\n",
        "    # Get the total number of rows\n",
        "    total_rows = len(df)\n",
        "\n",
        "    print(f'Average length of text1: {average_length_text1:.2f} characters')\n",
        "    print(f'Average length of text2: {average_length_text2:.2f} characters')\n",
        "    print(f'Overall average length of texts: {overall_average_length:.2f} characters')\n",
        "    print(f'Total number of rows: {total_rows}')"
      ],
      "metadata": {
        "id": "xzbcLfayT5fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entityremove(df):\n",
        "    texts = df['text1'].tolist() + df['text2'].tolist()\n",
        "    processed_texts = replace_named_entities(texts)\n",
        "    df['text1'] = processed_texts[:len(df)]\n",
        "    df['text2'] = processed_texts[len(df):]\n",
        "    lengths_df(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "DYTtIgjBidcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imdb\n",
        "imdb = pd.read_parquet(\"hf://datasets/tasksource/imdb62/data/train-00000-of-00001-62894f3b39974716.parquet\")\n",
        "columns_to_keep = [\"content\", \"userId\"]\n",
        "imdb = imdb[columns_to_keep]\n",
        "imdb_df = imdb.rename(columns={'userId': 'id', 'content':'text'})\n",
        "print(len(imdb_df))\n",
        "imdb_df = imdb_df[imdb_df['text'].str.strip().astype(bool)]\n",
        "print(len(imdb_df))\n",
        "#61987\n",
        "#61973"
      ],
      "metadata": {
        "id": "8iRjGbkZTt0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_imdb_df = create_balanced_pairs(imdb_df)\n",
        "# Number of same author pairs: 15494\n",
        "\n",
        "# Number of different author pairs: 15491\n"
      ],
      "metadata": {
        "id": "6oAUc5WLTyXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = balanced_imdb_df['text1'].tolist() + balanced_imdb_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "# Split the processed texts back into text1 and text2\n",
        "balanced_imdb_df['text1'] = processed_texts[:len(balanced_imdb_df)]\n",
        "balanced_imdb_df['text2'] = processed_texts[len(balanced_imdb_df):]\n",
        "imdb = balanced_imdb_df"
      ],
      "metadata": {
        "id": "d3nGScEsUDBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb.head())\n",
        "lengths_df(imdb)\n",
        "'''\n",
        "Average length of text1: 1669.69 characters\n",
        "Average length of text2: 1667.14 characters\n",
        "Overall average length of texts: 1668.41 characters\n",
        "Total number of rows: 30982\n",
        "'''"
      ],
      "metadata": {
        "id": "w-3A1MY8UEbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the combined dataframe\n",
        "imdb_train, imdb_val, imdb_test = train_test_val_split(imdb, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42)\n",
        "\n",
        "# Display the sizes of the resulting DataFrames\n",
        "print(f'Train set size: {len(imdb_train)}')\n",
        "print(f'Validation set size: {len(imdb_val)}')\n",
        "print(f'Test set size: {len(imdb_test)}')\n",
        "'''\n",
        "Train set size: 21687\n",
        "Validation set size: 4647\n",
        "Test set size: 4648\n",
        "'''"
      ],
      "metadata": {
        "id": "OnEt74t3UQCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#arxiv\n",
        "arxiv = pd.read_csv('arxiv.csv', encoding='latin1')\n",
        "columns_to_keep = [\"abstract\", \"author\"]\n",
        "arxiv = arxiv[columns_to_keep]\n",
        "arxiv_df = arxiv.rename(columns={'author': 'id', 'abstract':'text'})"
      ],
      "metadata": {
        "id": "1bacvNc6UIEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_arxiv_df = create_balanced_pairs(arxiv_df)\n",
        "# Number of same author pairs: 352\n",
        "\n",
        "# Number of different author pairs: 357\n"
      ],
      "metadata": {
        "id": "TamDRi7WUKRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = balanced_arxiv_df['text1'].tolist() + balanced_arxiv_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "# Split the processed texts back into text1 and text2\n",
        "balanced_arxiv_df['text1'] = processed_texts[:len(balanced_arxiv_df)]\n",
        "balanced_arxiv_df['text2'] = processed_texts[len(balanced_arxiv_df):]\n",
        "arxiv = balanced_arxiv_df"
      ],
      "metadata": {
        "id": "gBCm8wxzUOZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(arxiv.head())\n",
        "lengths_df(arxiv)\n",
        "'''\n",
        "Average length of text1: 812.71 characters\n",
        "Average length of text2: 793.66 characters\n",
        "Overall average length of texts: 803.18 characters\n",
        "Total number of rows: 704\n",
        "'''"
      ],
      "metadata": {
        "id": "vZdW-AD8UOzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the combined dataframe\n",
        "arxiv_train, arxiv_val, arxiv_test = train_test_val_split(arxiv, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42)\n",
        "\n",
        "# Display the sizes of the resulting DataFrames\n",
        "print(f'Train set size: {len(arxiv_train)}')\n",
        "print(f'Validation set size: {len(arxiv_val)}')\n",
        "print(f'Test set size: {len(arxiv_test)}')\n",
        "'''\n",
        "Train set size: 492\n",
        "Validation set size: 106\n",
        "Test set size: 106\n",
        "'''"
      ],
      "metadata": {
        "id": "KACq6ktpUX-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_train.to_csv('arxiv_train.csv', index=False)\n",
        "arxiv_val.to_csv('arxiv_val.csv', index=False)\n",
        "arxiv_test.to_csv('arxiv_test.csv', index=False)\n",
        "\n",
        "imdb_train.to_csv('imdb_train.csv', index=False)\n",
        "imdb_val.to_csv('imdb_val.csv', index=False)\n",
        "imdb_test.to_csv('imdb_test.csv', index=False)"
      ],
      "metadata": {
        "id": "cyicDa_aUjap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reuters\n",
        "download(reuters, 'reuters')\n",
        "'''\n",
        "Train set size: 841\n",
        "Validation set size: 180\n",
        "Test set size: 181\n",
        "'''"
      ],
      "metadata": {
        "id": "O2VG-SOPXhum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_folder = 'Desktop/datasets/reuters50'\n",
        "data = load_texts_from_folders(base_folder)\n",
        "balanced_pairs = create_unique_text_pairs(data)\n",
        "# 601\n",
        "# 625\n",
        "balanced_df = pd.DataFrame(balanced_pairs, columns=['text1', 'text2', 'same'])"
      ],
      "metadata": {
        "id": "NpJAnsGQXi3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = balanced_df['text1'].tolist() + balanced_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "# Split the processed texts back into text1 and text2\n",
        "balanced_df['text1'] = processed_texts[:len(balanced_df)]\n",
        "balanced_df['text2'] = processed_texts[len(balanced_df):]\n",
        "reuters = balanced_df"
      ],
      "metadata": {
        "id": "s9SAgdCmXvRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_df(reuters)\n",
        "'''\n",
        "Average length of text1: 2786.62 characters\n",
        "Average length of text2: 2753.46 characters\n",
        "Overall average length of texts: 2770.04 characters\n",
        "Total number of rows: 1202\n",
        "'''"
      ],
      "metadata": {
        "id": "3UJrfzvbX0dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#blogs\n",
        "\n",
        "blogs = pd.read_csv('Desktop/datasets/blogs.csv')\n",
        "\n",
        "columns_to_keep = [\"id\", \"text\"]\n",
        "\n",
        "blogs_section = blogs[columns_to_keep]"
      ],
      "metadata": {
        "id": "DEDKlETyYCy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blogs_section = blogs_section[blogs_section['text'].str.strip().astype(bool)]\n",
        "blogs_section = blogs_section.drop_duplicates()\n",
        "print(len(blogs_section))\n",
        "#672735\n",
        "balanced_blog_df = create_balanced_pairs(blogs_section, reserve_ratio=0.1)\n",
        "#Number of same author pairs: 301938\n",
        "#Number of different author pairs: 29465"
      ],
      "metadata": {
        "id": "CaIuX71aYT2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = balanced_blog_df['text1'].tolist() + balanced_blog_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "# Split the processed texts back into text1 and text2\n",
        "balanced_blog_df['text1'] = processed_texts[:len(balanced_blog_df)]\n",
        "balanced_blog_df['text2'] = processed_texts[len(balanced_blog_df):]\n",
        "blogs = balanced_blog_df"
      ],
      "metadata": {
        "id": "EtQ7r7-UYg-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(blogs.head())\n",
        "lengths_df(blogs)\n",
        "'''Average length of text1: 1107.91 characters\n",
        "Average length of text2: 1063.41 characters\n",
        "Overall average length of texts: 1085.66 characters\n",
        "Total number of rows: 58930'''"
      ],
      "metadata": {
        "id": "QcqVsc-5YjBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(blogs, 'blogs')\n",
        "# Train set size: 41251\n",
        "# Validation set size: 8839\n",
        "# Test set size: 8840"
      ],
      "metadata": {
        "id": "WZ1UMSiAmBAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#victorian\n",
        "victorian_dset= pd.read_csv('Desktop/datasets/victorian.csv', encoding='latin1')\n",
        "victorian_dset = victorian_dset.rename(columns={'author': 'id'})\n",
        "victorian_dset = victorian_dset[victorian_dset['text'].str.strip().astype(bool)]\n",
        "balanced_victorian_df = create_balanced_pairs(victorian_dset)\n",
        "'''\n",
        "Creating same author pairs and reserving texts: 100%|█| 45/45 [00:00<00:00, 256.\n",
        "Number of same author pairs: 21470\n",
        "Creating different author pairs: 100%|████| 5359/5359 [00:01<00:00, 4050.85it/s]\n",
        "Number of different author pairs: 5359'''"
      ],
      "metadata": {
        "id": "Ql1pISxZYnf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = balanced_victorian_df['text1'].tolist() + balanced_victorian_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "balanced_victorian_df['text1'] = processed_texts[:len(balanced_victorian_df)]\n",
        "balanced_victorian_df['text2'] = processed_texts[len(balanced_victorian_df):]\n",
        "victorian = balanced_victorian_df\n",
        "#100%|███████████████████████████████████| 21436/21436 [1:25:52<00:00,  4.16it/s]\n"
      ],
      "metadata": {
        "id": "FovcfKlHY1Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(victorian.head())\n",
        "lengths_df(victorian)\n",
        "'''Average length of text1: 4925.94 characters\n",
        "Average length of text2: 4920.34 characters\n",
        "Overall average length of texts: 4923.14 characters\n",
        "Total number of rows: 10718'''"
      ],
      "metadata": {
        "id": "jam94MUWY51y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(victorian, 'victorian')\n",
        "#Train set size: 7502\n",
        "# Validation set size: 1608\n",
        "# Test set size: 1608"
      ],
      "metadata": {
        "id": "0NstplzRmXnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#darkreddit\n",
        "directory = 'Desktop/datasets/darkreddit'\n",
        "\n",
        "darkreddit_train_df, darkreddit_test_df, darkreddit_val_df = process_darkreddit(directory)\n",
        "\n",
        "print(\"Train DataFrame:\")\n",
        "print(darkreddit_train_df.head())\n",
        "print(\"Test DataFrame:\")\n",
        "print(darkreddit_test_df.head())\n",
        "print(\"Val DataFrame:\")\n",
        "print(darkreddit_val_df.head())\n",
        "'''\n",
        "Number of JSON files in train split: 204\n",
        "Processing train files: 100%|█████████████████| 204/204 [01:19<00:00,  2.55it/s]\n",
        "Number of JSON files in test split: 412\n",
        "Processing test files: 100%|██████████████████| 412/412 [02:06<00:00,  3.25it/s]\n",
        "Number of JSON files in val split: 412\n",
        "Processing val files: 100%|███████████████████| 412/412 [02:13<00:00,  3.08it/s]\n",
        "'''\n",
        "\n",
        "df_name = 'darkreddit'\n",
        "darkreddit_train_df.to_csv(f'Desktop/{df_name}_train.csv', index=False)\n",
        "darkreddit_test_df.to_csv(f'Desktop/{df_name}_val.csv', index=False)\n",
        "darkreddit_val_df.to_csv(f'Desktop/{df_name}_test.csv', index=False)"
      ],
      "metadata": {
        "id": "s_sSdRZ6cGan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#british\n",
        "directory = 'Desktop/datasets/british'\n",
        "\n",
        "texts_by_author = read_texts(directory)\n",
        "\n",
        "pairs = create_pairs(texts_by_author)\n",
        "random.shuffle(pairs)\n",
        "\n",
        "british_df = pd.DataFrame(pairs, columns=['text1', 'text2', 'same'])\n",
        "# Same author pairs: 575\n",
        "# Different author pairs: 611"
      ],
      "metadata": {
        "id": "J5UJd_dyc-3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = british_df['text1'].tolist() + british_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "# Split the processed texts back into text1 and text2\n",
        "british_df['text1'] = processed_texts[:len(british_df)]\n",
        "british_df['text2'] = processed_texts[len(british_df):]\n",
        "british = british_df\n",
        "#Processing texts: 100%|█████████████████████| 2300/2300 [28:04<00:00,  1.37it/s]"
      ],
      "metadata": {
        "id": "fyYLGnEodDhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_df(british_df)\n",
        "'''Average length of text1: 14850.00 characters\n",
        "Average length of text2: 14554.32 characters\n",
        "Overall average length of texts: 14702.16 characters\n",
        "Total number of rows: 1150'''"
      ],
      "metadata": {
        "id": "7qJzNgxxdWjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "british = british_df\n",
        "download(british, \"british\")\n",
        "'''805, 172, 173'''"
      ],
      "metadata": {
        "id": "FqEYq0v_eC2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pan11\n",
        "text_file_path = 'Desktop/datasets/pan11/LargeTrain.txt'\n",
        "\n",
        "df = parse_training_text(text_file_path)\n",
        "balanced_pan11_df = create_balanced_pairs(df)\n",
        "'''Creating same author pairs and reserving texts: 100%|█| 72/72 [00:00<00:00, 1428\n",
        "Number of same author pairs: 2326\n",
        "Creating different author pairs: 100%|████| 2325/2325 [00:00<00:00, 3904.26it/s]\n",
        "Number of different author pairs: 2325'''"
      ],
      "metadata": {
        "id": "GafCXKSQeT6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = balanced_pan11_df['text1'].tolist() + balanced_pan11_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "balanced_pan11_df['text1'] = processed_texts[:len(balanced_pan11_df)]\n",
        "balanced_pan11_df['text2'] = processed_texts[len(balanced_pan11_df):]\n",
        "pan11_train = balanced_pan11_df\n",
        "'''100%|███████████████████████████████████████| 9300/9300 [08:40<00:00, 17.88it/s]\n",
        "'''\n",
        "print(pan11_train.head())\n",
        "lengths_df(pan11_train)\n",
        "'''Average length of text1: 290.13 characters\n",
        "Average length of text2: 311.80 characters\n",
        "Overall average length of texts: 300.96 characters\n",
        "Total number of rows: 4650'''"
      ],
      "metadata": {
        "id": "MqgNqvrjegGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan11 = pan11_train\n",
        "download(pan11, \"pan11\")\n",
        "'''Train set size: 3255\n",
        "Validation set size: 697\n",
        "Test set size: 698'''"
      ],
      "metadata": {
        "id": "DOrdF04nexXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pan13\n",
        "train_directory = 'Desktop/datasets/pan13/train'\n",
        "test_directory = 'Desktop/datasets/pan13/test'\n",
        "\n",
        "pan13_train_df = process_folder(train_directory)\n",
        "pan13_test_df = process_folder(test_directory)"
      ],
      "metadata": {
        "id": "urFFH43Ce-Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = pan13_test_df['text1'].tolist() + pan13_test_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "pan13_test_df['text1'] = processed_texts[:len(pan13_test_df)]\n",
        "pan13_test_df['text2'] = processed_texts[len(pan13_test_df):]\n",
        "lengths_df(pan13_test_df)\n",
        "'''Average length of text1: 7391.20 characters\n",
        "Average length of text2: 7575.74 characters\n",
        "Overall average length of texts: 7483.47 characters\n",
        "Total number of rows: 35'''"
      ],
      "metadata": {
        "id": "lfBcKxZbfVyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = pan13_train_df['text1'].tolist() + pan13_train_df['text2'].tolist()\n",
        "processed_texts = replace_named_entities(texts)\n",
        "# Split the processed texts back into text1 and text2\n",
        "pan13_train_df['text1'] = processed_texts[:len(pan13_train_df)]\n",
        "pan13_train_df['text2'] = processed_texts[len(pan13_train_df):]\n",
        "lengths_df(pan13_train_df)\n",
        "# 100%|█████████████████████████████████████████| 170/170 [00:53<00:00,  3.16it/s]\n",
        "# Average length of text1: 6879.89 characters\n",
        "# Average length of text2: 7125.55 characters\n",
        "# Overall average length of texts: 7002.72 characters\n",
        "# Total number of rows: 85"
      ],
      "metadata": {
        "id": "BhkWhISlfhfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan13_train_df.to_csv('Desktop/pan13_train.csv', index=False)\n",
        "pan13_val, pan13_test = train_test_split(pan13_test_df, test_size=0.5, random_state=42)\n",
        "\n",
        "pan13_test.to_csv('Desktop/pan13_test.csv', index=False)\n",
        "pan13_val.to_csv('Desktop/pan13_val.csv', index=False)"
      ],
      "metadata": {
        "id": "ZNcV9Ryzg1qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pan14\n",
        "def process_folder(directory):\n",
        "    truth_file_path = os.path.join(directory, 'truth.txt')\n",
        "    labels = {}\n",
        "\n",
        "    with open(truth_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.strip():  # Ignore empty lines\n",
        "                folder_name, same_author = line.strip().split()\n",
        "                labels[folder_name] = same_author == 'Y'\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for folder_name, same_author in labels.items():\n",
        "        folder_path = os.path.join(directory, folder_name)\n",
        "        known_file_path = os.path.join(folder_path, 'known01.txt')\n",
        "        unknown_file_path = os.path.join(folder_path, 'unknown.txt')\n",
        "\n",
        "        with open(known_file_path, 'r') as known_file:\n",
        "            known_text = known_file.read()\n",
        "\n",
        "        with open(unknown_file_path, 'r') as unknown_file:\n",
        "            unknown_text = unknown_file.read()\n",
        "\n",
        "        data.append({'text1': known_text, 'text2': unknown_text, 'same': same_author})\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "\n",
        "novels_train_dir = 'Desktop/datasets/pan14/novels'\n",
        "novels_test_dir = 'Desktop/datasets/pan14/novelstest'\n",
        "novels_verify_dir = 'Desktop/datasets/pan14/novelsverify'\n",
        "\n",
        "essays_train_dir = 'Desktop/datasets/pan14/essays'\n",
        "essays_test_dir = 'Desktop/datasets/pan14/essaystest'\n",
        "essays_verify_dir = 'Desktop/datasets/pan14/essaysverify'\n",
        "\n",
        "novels_train_df = process_folder(novels_train_dir)\n",
        "novels_test_df = process_folder(novels_test_dir)\n",
        "novels_verify_df = process_folder(novels_verify_dir)\n",
        "\n",
        "essays_train_df = process_folder(essays_train_dir)\n",
        "essays_test_df = process_folder(essays_test_dir)\n",
        "essays_verify_df = process_folder(essays_verify_dir)\n",
        "\n",
        "print(\"Novels Train DataFrame\")\n",
        "print(novels_train_df.head())\n",
        "print(\"Novels Test DataFrame\")\n",
        "print(novels_test_df.head())\n",
        "print(\"Novels Verify DataFrame\")\n",
        "print(novels_verify_df.head())\n",
        "\n",
        "print(\"Essays Train DataFrame\")\n",
        "print(essays_train_df.head())\n",
        "print(\"Essays Test DataFrame\")\n",
        "print(essays_test_df.head())\n",
        "print(\"Essays Verify DataFrame\")\n",
        "print(essays_verify_df.head())"
      ],
      "metadata": {
        "id": "QyJ48CEKh3PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan14_train = pd.concat([novels_train_df, essays_train_df], ignore_index=True)\n",
        "pan14_test = pd.concat([novels_test_df, essays_test_df], ignore_index=True)\n",
        "pan14_verify = pd.concat([novels_verify_df, essays_verify_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "znsDMxHJh9TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_df(pan14_train)\n",
        "lengths_df(pan14_test)\n",
        "lengths_df(pan14_verify)\n",
        "'''Average length of text1: 12483.33 characters\n",
        "Average length of text2: 16039.48 characters\n",
        "Overall average length of texts: 14261.41 characters\n",
        "Total number of rows: 300\n",
        "Average length of text1: 16717.15 characters\n",
        "Average length of text2: 22049.04 characters\n",
        "Overall average length of texts: 19383.10 characters\n",
        "Total number of rows: 400\n",
        "Average length of text1: 15021.18 characters\n",
        "Average length of text2: 7249.65 characters\n",
        "Overall average length of texts: 11135.42 characters\n",
        "Total number of rows: 200'''"
      ],
      "metadata": {
        "id": "6Fgoz_5giBZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan14_train.to_csv('Desktop/pan14_train.csv', index=False)\n",
        "pan14_test.to_csv('Desktop/pan14_test.csv', index=False)\n",
        "pan14_verify.to_csv('Desktop/pan14_val.csv', index=False)"
      ],
      "metadata": {
        "id": "MlxI413liCHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pan15\n",
        "\n",
        "def process_pan15_folder(directory):\n",
        "    data = []\n",
        "    labels = {}\n",
        "\n",
        "    for subdir in os.listdir(directory):\n",
        "        subdir_path = os.path.join(directory, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            truth_file_path = os.path.join(subdir_path, 'truth.txt')\n",
        "            with open(truth_file_path, 'r') as file:\n",
        "                for line in file:\n",
        "                    if line.strip():\n",
        "                        folder_name, same_author = line.strip().split()\n",
        "                        labels[folder_name] = same_author == 'Y'\n",
        "\n",
        "            for folder in os.listdir(subdir_path):\n",
        "                folder_path = os.path.join(subdir_path, folder)\n",
        "                if os.path.isdir(folder_path):\n",
        "                    known_file_path = os.path.join(folder_path, 'known01.txt')\n",
        "                    unknown_file_path = os.path.join(folder_path, 'unknown.txt')\n",
        "                    with open(known_file_path, 'r', errors='ignore') as known_file, open(unknown_file_path, 'r', errors='ignore') as unknown_file:\n",
        "                        known_text = known_file.read().strip()\n",
        "                        unknown_text = unknown_file.read().strip()\n",
        "                        data.append({\n",
        "                            'text1': known_text,\n",
        "                            'text2': unknown_text,\n",
        "                            'same': labels[folder]\n",
        "                        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "pan15_train_directory = 'Desktop/datasets/pan15/train'\n",
        "pan15_test_directory = 'Desktop/datasets/pan15/test'\n",
        "\n",
        "pan15_train_df = process_pan15_folder(pan15_train_directory)\n",
        "pan15_test_df = process_pan15_folder(pan15_test_directory)\n",
        "\n",
        "print(pan15_train_df.head())\n",
        "print(pan15_test_df.head())\n"
      ],
      "metadata": {
        "id": "JRBvOycriban"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan15_train_df.to_csv('Desktop/pan15_train.csv', index=False)\n",
        "\n",
        "pan15_val, pan15_test = train_test_split(pan15_test_df, test_size=0.5, random_state=42)\n",
        "\n",
        "pan15_test.to_csv('Desktop/pan15_test.csv', index=False)\n",
        "pan15_val.to_csv('Desktop/pan15_val.csv', index=False)\n",
        "\n",
        "lengths_df(pan15_train_df)\n",
        "lengths_df(pan15_val)\n",
        "lengths_df(pan15_test)\n",
        "'''Average length of text1: 3373.92 characters\n",
        "Average length of text2: 2787.31 characters\n",
        "Overall average length of texts: 3080.61 characters\n",
        "Total number of rows: 865\n",
        "Average length of text1: 3571.18 characters\n",
        "Average length of text2: 3264.16 characters\n",
        "Overall average length of texts: 3417.67 characters\n",
        "Total number of rows: 200\n",
        "Average length of text1: 3421.29 characters\n",
        "Average length of text2: 3161.57 characters\n",
        "Overall average length of texts: 3291.43 characters\n",
        "Total number of rows: 200'''"
      ],
      "metadata": {
        "id": "1NsB4VQAiopb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pan20\n",
        "def load_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            data.append(json.loads(line))\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "pan20_train_file = 'Desktop/datasets/pan20/train.jsonl'\n",
        "pan20_test_file = 'Desktop/datasets/pan20/test.jsonl'\n",
        "pan20_val_file = 'Desktop/datasets/pan20/val.jsonl'\n",
        "\n",
        "pan20_val_df = load_jsonl(pan20_val_file)"
      ],
      "metadata": {
        "id": "Pf4UGRqFjRCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = [\"same\", \"pair\"]\n",
        "\n",
        "pan20_val_df = pan20_val_df[columns_to_keep]\n",
        "pan20_val_df['same'] = pan20_val_df['same'].astype(int)\n",
        "\n",
        "# Split 'pair' column into 'text1' and 'text2'\n",
        "pan20_val_df['text1'] = pan20_val_df['pair'].apply(lambda x: x[0])\n",
        "pan20_val_df['text2'] = pan20_val_df['pair'].apply(lambda x: x[1])\n",
        "\n",
        "# Drop the 'pair' column\n",
        "pan20_val_df = pan20_val_df.drop(columns=['pair'])\n",
        "\n",
        "pan20_val_df.head()"
      ],
      "metadata": {
        "id": "3lGjxrJtjX6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan20_train_df = load_jsonl(pan20_train_file)\n",
        "pan20_test_df = load_jsonl(pan20_test_file)\n",
        "\n",
        "pan20_train_df = pan20_train_df[columns_to_keep]\n",
        "pan20_train_df['same'] = pan20_train_df['same'].astype(int)\n",
        "\n",
        "# Split 'pair' column into 'text1' and 'text2'\n",
        "pan20_train_df['text1'] = pan20_train_df['pair'].apply(lambda x: x[0])\n",
        "pan20_train_df['text2'] = pan20_train_df['pair'].apply(lambda x: x[1])\n",
        "\n",
        "# Drop the 'pair' column\n",
        "pan20_train_df = pan20_train_df.drop(columns=['pair'])\n"
      ],
      "metadata": {
        "id": "YiydmNHzjddZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan20_test_df = pan20_test_df[columns_to_keep]\n",
        "pan20_test_df['same'] = pan20_test_df['same'].astype(int)\n",
        "\n",
        "# Split 'pair' column into 'text1' and 'text2'\n",
        "pan20_test_df['text1'] = pan20_test_df['pair'].apply(lambda x: x[0])\n",
        "pan20_test_df['text2'] = pan20_test_df['pair'].apply(lambda x: x[1])\n",
        "\n",
        "# Drop the 'pair' column\n",
        "pan20_test_df = pan20_test_df.drop(columns=['pair'])\n",
        "\n",
        "pan20_test_df.head()"
      ],
      "metadata": {
        "id": "IGaggIu8jjMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# texts = pan20_val_df['text1'].tolist() + pan20_val_df['text2'].tolist()\n",
        "# processed_texts = replace_named_entities(texts)\n",
        "# # Split the processed texts back into text1 and text2\n",
        "# pan20_val_df['text1'] = processed_texts[:len(pan20_val_df)]\n",
        "# pan20_val_df['text2'] = processed_texts[len(pan20_val_df):]\n",
        "# pan20_val_df = pan20_val_df"
      ],
      "metadata": {
        "id": "V5gJkoNujlrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_df(pan20_train_df)\n",
        "lengths_df(pan20_test_df)\n",
        "lengths_df(pan20_val_df)\n",
        "'''\n",
        "Average length of text1: 21470.89 characters\n",
        "Average length of text2: 21476.11 characters\n",
        "Overall average length of texts: 21473.50 characters\n",
        "Total number of rows: 248001\n",
        "Average length of text1: 21418.08 characters\n",
        "Average length of text2: 21400.72 characters\n",
        "Overall average length of texts: 21409.40 characters\n",
        "Total number of rows: 13704\n",
        "Average length of text1: 21490.78 characters\n",
        "Average length of text2: 21551.04 characters\n",
        "Overall average length of texts: 21520.91 characters\n",
        "Total number of rows: 13703\n",
        "'''"
      ],
      "metadata": {
        "id": "UNw81L03joTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pan20_train_df.to_csv('Desktop/pan20_train.csv', index=False)\n",
        "pan20_test_df.to_csv('Desktop/pan20_test.csv', index=False)\n",
        "pan20_val_df.to_csv('Desktop/pan20_val.csv', index=False)"
      ],
      "metadata": {
        "id": "NCsY5VuLkI7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}